{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Softmax\n",
    "### $\\sigma(z_i)=\\frac{e^{z_i}}{\\sum_{j=0}^K e^{z_j}}$for $i=1,.....,K$ and $z=(z_1,....,z_k)\\in R^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(L):\n",
    "    exp_l = np.exp(L)\n",
    "    return np.divide(exp_l, exp_l.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [5,6,7]\n",
    "softmax(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return np.divide(1, 1+np.exp(np.dot(-1, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.72007598e-44, 4.53978687e-05, 5.00000000e-01, 9.99954602e-01,\n",
       "       1.00000000e+00])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([-100, -10, 0, 10, 100])\n",
    "sigmoid(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Cross Etropy\n",
    "### $Cross-Entropy= -\\sum_{i=0}^n y_iln(p_i)+(1-y_i)ln(1-p_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1-Y) * np.log(1-P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6851790109107685"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[1,1,0]\n",
    "p=[0.8,0.7,0.1]\n",
    "cross_entropy(Y,p) # Expected 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction formula\n",
    "$\\hat{y}=\\sigma(WX+b)=w_1x_1+w_2x_2+......+w_nx_n+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    y_hat = sigmoid(np.matmul(features,weights)+bias)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=[1,1]\n",
    "features=[1,1]\n",
    "bias=-1\n",
    "output = output_formula(features, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return -y * np.log(output) - (1 - y) * np.log(1 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31326169])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array([1])\n",
    "error_formula(y,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    y_hat = output_formula(x, weights, bias)\n",
    "    error = y - y_hat\n",
    "    weights = weights + learnrate * error * x\n",
    "    bias = bias +  learnrate * error\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.00349853,  1.24460059]), array([1.00022432]))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([1,1])\n",
    "weights = np.random.normal(scale=1 / 2**.5, size=2)\n",
    "y=np.array([1])\n",
    "bias=1\n",
    "update_weights(x,y,weights, bias, 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
